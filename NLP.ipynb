{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxPj6X7N1QAyTS5p4EDpqw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thekhush11/GenAI-Colab-Projects/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NLP -\n",
        "1. Tokenization\n",
        "2. Embedding (Word2Vec, Glove)\n",
        "3. Bag-of-Word and TF-IDP"
      ],
      "metadata": {
        "id": "kbwUQikWBGiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP - Natural Language Processing is a branch of Artificial Intelligence that helps computer to understand, interprete, generate human languaga.\n",
        "\n",
        "NLP Applications - Search Engine, Chatbots, Email Filtering, Speech to text, Grammer correction, Sentiment Analysis.\n",
        "\n",
        "NLP Steps -\n",
        "\n",
        "---\n",
        "Tokenization -\n",
        "Remove Stopwords\n",
        "Stemming\n",
        "Vectorization\n",
        "Model Prediction\n",
        "\n",
        "Basic Input -\n",
        "\"NLP is the best branch of AI\"\n",
        "\"MLP\"\"is\"\"the\"\"best\"\"brance\"\"of\"\"AI\""
      ],
      "metadata": {
        "id": "z6OdDWldB3bt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVe94HnB_uqU",
        "outputId": "fb5af693-100e-4751-bb11-332cfa68fa1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I\n",
            "’\n",
            "m\n",
            "thrilled\n",
            "to\n",
            "share\n",
            "that\n",
            "I\n",
            "’\n",
            "ve\n",
            "earned\n",
            "the\n",
            "50\n",
            "Days\n",
            "Badge\n",
            "2025\n",
            "on\n",
            "LeetCode\n",
            "!\n",
            "This\n",
            "represents\n",
            "50+\n",
            "days\n",
            "of\n",
            "consistent\n",
            "problem-solving\n",
            ",\n",
            "learning\n",
            ",\n",
            "and\n",
            "growing\n",
            "in\n",
            "the\n",
            "world\n",
            "of\n",
            "data\n",
            "structures\n",
            "and\n",
            "algorithms\n",
            ".\n",
            "40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk #nltk is the python librabry that is used for working in human language data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Download the missing resource\n",
        "from nltk.tokenize import word_tokenize\n",
        "data = \"I’m thrilled to share that I’ve earned the 50 Days Badge 2025 on LeetCode! This represents 50+ days of consistent problem-solving, learning, and growing in the world of data structures and algorithms.\"\n",
        "Processed_Data = word_tokenize(data)\n",
        "for i in Processed_Data:\n",
        "  print(i)\n",
        "print(len(Processed_Data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "Data1 = set(stopwords.words('english'))\n",
        "data2 = []\n",
        "for i in Processed_Data:\n",
        "  if i.lower() not in Data1:\n",
        "    data2.append(Processed_Data)\n",
        "print(len(data2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxJUq2JzIhCd",
        "outputId": "e625274b-bfba-4571-ae8c-65f9fb75c3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stemming -\n",
        "Reduce word to there base root or form"
      ],
      "metadata": {
        "id": "xlf1euuyPeXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "Stemmer = PorterStemmer()\n",
        "data3 = []\n",
        "for i in Processed_Data:\n",
        "  data3.append(Stemmer.stem(i))\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-7GutzgNQzw",
        "outputId": "7c71f53c-b258-4cdf-e80a-dbb44f826131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', '’', 'm', 'thrill', 'to', 'share', 'that', 'i', '’', 've', 'earn', 'the', '50', 'day', 'badg', '2025', 'on', 'leetcod', '!', 'thi', 'repres', '50+', 'day', 'of', 'consist', 'problem-solv', ',', 'learn', ',', 'and', 'grow', 'in', 'the', 'world', 'of', 'data', 'structur', 'and', 'algorithm', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vectorization -\n",
        "It is a techniques that convert text into a numeric vector\n",
        "#Type of Vectorization -\n",
        "1. Bag of Words (BoW) - Bag of words count a word how many times appears in a whole documents\n",
        "2. TF-IDF\n",
        "3. Embedding"
      ],
      "metadata": {
        "id": "69BTk15XU0ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text = [\"Natural Language Processing (NLP) is a branch of artificial intelligence (AI) that enables computers to understand, interpret, manipulate, and generate human language.\", \"It's an interdisciplinary field that combines computer science, AI, and linguistics to process large amounts of text and speech data.\"]\n",
        "\n",
        "Vector = CountVectorizer()\n",
        "New_text = Vector.fit_transform(text)\n",
        "print(Vector.get_feature_names_out())\n",
        "print(New_text.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MHhmDmCRQTi",
        "outputId": "0da1018e-dd89-4f59-ab26-1a13b0f8e3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'amounts' 'an' 'and' 'artificial' 'branch' 'combines' 'computer'\n",
            " 'computers' 'data' 'enables' 'field' 'generate' 'human' 'intelligence'\n",
            " 'interdisciplinary' 'interpret' 'is' 'it' 'language' 'large'\n",
            " 'linguistics' 'manipulate' 'natural' 'nlp' 'of' 'process' 'processing'\n",
            " 'science' 'speech' 'text' 'that' 'to' 'understand']\n",
            "[[1 0 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 0 2 0 0 1 1 1 1 0 1 0 0 0 1 1 1]\n",
            " [1 1 1 2 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IF - TDF\n",
        "\n",
        "IF - How frequently they appear in the whole documnet\n",
        "\n",
        "IDF - how rear they are in the whole document"
      ],
      "metadata": {
        "id": "UeMV_Zg8aXXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "vectors = tfidf.fit_transform(text)\n",
        "print(tfidf.get_feature_names_out())\n",
        "print(vectors.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2ZtYNu_XFed",
        "outputId": "7c8a16eb-1875-4e55-e504-81f4c496be67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ai' 'amounts' 'an' 'and' 'artificial' 'branch' 'combines' 'computer'\n",
            " 'computers' 'data' 'enables' 'field' 'generate' 'human' 'intelligence'\n",
            " 'interdisciplinary' 'interpret' 'is' 'it' 'language' 'large'\n",
            " 'linguistics' 'manipulate' 'natural' 'nlp' 'of' 'process' 'processing'\n",
            " 'science' 'speech' 'text' 'that' 'to' 'understand']\n",
            "[[0.15702636 0.         0.         0.15702636 0.22069507 0.22069507\n",
            "  0.         0.         0.22069507 0.         0.22069507 0.\n",
            "  0.22069507 0.22069507 0.22069507 0.         0.22069507 0.22069507\n",
            "  0.         0.44139013 0.         0.         0.22069507 0.22069507\n",
            "  0.22069507 0.15702636 0.         0.22069507 0.         0.\n",
            "  0.         0.15702636 0.15702636 0.22069507]\n",
            " [0.16747189 0.23537589 0.23537589 0.33494377 0.         0.\n",
            "  0.23537589 0.23537589 0.         0.23537589 0.         0.23537589\n",
            "  0.         0.         0.         0.23537589 0.         0.\n",
            "  0.23537589 0.         0.23537589 0.23537589 0.         0.\n",
            "  0.         0.16747189 0.23537589 0.         0.23537589 0.23537589\n",
            "  0.23537589 0.16747189 0.16747189 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding -\n",
        "Word Embedding is mapped each word to a vector of real number\n",
        "* Types of Embedding -\n",
        "1. Word2Vec\n",
        "2. Glove"
      ],
      "metadata": {
        "id": "N2QqCokJeEv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "#model1 = api.load(\"word2vec-google-news-300\") (Very Big Data)\n",
        "model1 = api.load(\"glove-wiki-gigaword-50\")\n",
        "print(model1)"
      ],
      "metadata": {
        "id": "1gDqyrM3f16C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47075e1-4159-4b60-a8ee-d83b353ae3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KeyedVectors<vector_size=50, 400000 keys>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model1['computer']\n",
        "print(vector[:10])"
      ],
      "metadata": {
        "id": "2RBW2xrtf_QM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef01d25-f3d3-46a0-d87e-3a4cd3e72369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.079084 -0.81504   1.7901    0.91653   0.10797  -0.55628  -0.84427\n",
            " -1.4951    0.13418   0.63627 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simi = model1.most_similar(\"computer\", topn = 5)\n",
        "for i in simi:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR4uV4MBh_GR",
        "outputId": "da673aab-650e-4176-8596-ae866ba4ca9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('computers', 0.9165045022964478)\n",
            "('software', 0.8814992904663086)\n",
            "('technology', 0.852556049823761)\n",
            "('electronic', 0.812586784362793)\n",
            "('internet', 0.8060455322265625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Mechanism\n",
        "! pip install torch # installing pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90aed0eb-5464-4069-d867-2d8935733536",
        "id": "KOj5iO2lqE4J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as fn"
      ],
      "metadata": {
        "id": "HNFDjs0-X12w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['The','Man','Work']\n",
        "print(text)\n",
        "\n",
        "e_d = 8\n",
        "\n",
        "w_idx = {i: index for index, i in enumerate(text)}\n",
        "print(w_idx)\n",
        "\n",
        "idx_w = torch.tensor([w_idx[i] for i in text])\n",
        "print(idx_w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIm8y0mPZ4I1",
        "outputId": "5cf31aa7-cf69-4c8a-fe91-69436a811a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Man', 'Work']\n",
            "{'The': 0, 'Man': 1, 'Work': 2}\n",
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed = nn.Embedding(num_embeddings=len(w_idx), embedding_dim=e_d)"
      ],
      "metadata": {
        "id": "y7Hudkglazcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeded = embed(idx_w)\n",
        "print(embeded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdJuCr_-bXnQ",
        "outputId": "a78ffe2f-1f77-428e-8715-59ca06862d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5570,  0.1775,  0.0736,  0.2351, -0.0933,  0.7444,  2.0711, -0.7837],\n",
            "        [ 0.3476, -0.6201, -1.1404, -0.4639, -0.4886, -0.5831, -1.8925,  0.7743],\n",
            "        [-0.6554, -1.5103, -0.2854,  0.0617,  1.1055, -1.4175,  1.0914,  1.1751]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeded = embeded.unsqueeze(0)\n",
        "embeded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLoDvhsQcBbR",
        "outputId": "d31374e4-b35b-431f-fdf6-70bb4d2e1d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5570,  0.1775,  0.0736,  0.2351, -0.0933,  0.7444,  2.0711,\n",
              "          -0.7837],\n",
              "         [ 0.3476, -0.6201, -1.1404, -0.4639, -0.4886, -0.5831, -1.8925,\n",
              "           0.7743],\n",
              "         [-0.6554, -1.5103, -0.2854,  0.0617,  1.1055, -1.4175,  1.0914,\n",
              "           1.1751]]], grad_fn=<UnsqueezeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_head = 2\n",
        "multi_head = nn.MultiheadAttention(embed_dim=e_d, num_heads=num_head, batch_first=True)"
      ],
      "metadata": {
        "id": "cub6ECc5ci7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkPXAZx8dbsc",
        "outputId": "fba25c0a-b0b8-4a97-eac3-e539de4c384f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiheadAttention(\n",
              "  (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_output, a_weights = multi_head(embeded, embeded, embeded)"
      ],
      "metadata": {
        "id": "kRKoFKMWdiHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUrmMrk2eFUb",
        "outputId": "b87d002b-09bb-4c51-d357-244f498b3b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3530, -0.1305,  0.0624, -0.0749,  0.0374,  0.1219,  0.0560,\n",
              "          -0.0416],\n",
              "         [ 0.2830, -0.1359,  0.0139, -0.0946,  0.0360,  0.0853,  0.0891,\n",
              "          -0.0794],\n",
              "         [ 0.2437, -0.1475,  0.0226, -0.0900,  0.0749,  0.0792,  0.0481,\n",
              "          -0.0613]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Aof2SDbejCw",
        "outputId": "f59be73c-7383-4c38-8f14-352adb561a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2682, 0.3547, 0.3771],\n",
              "         [0.2870, 0.3420, 0.3710],\n",
              "         [0.2780, 0.2874, 0.4346]]], grad_fn=<MeanBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Attention_weights = a_weights.squeeze(0).detach().numpy()\n",
        "print(Attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud_dYYLkeke5",
        "outputId": "117e775a-ee9b-41cd-e46d-43e415409369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26816154 0.35473323 0.37710524]\n",
            " [0.28703555 0.3419661  0.37099838]\n",
            " [0.27799302 0.2874279  0.43457907]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_output.squeeze(0).detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izqpV-WofrWT",
        "outputId": "6b5400f4-7bec-442a-87bb-0765dbb46928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.35296366, -0.13052626,  0.0623667 , -0.07486105,  0.03735699,\n",
              "         0.12187997,  0.05600118, -0.04160852],\n",
              "       [ 0.28301817, -0.13591531,  0.01385718, -0.09463891,  0.0360448 ,\n",
              "         0.08533718,  0.08911539, -0.07939664],\n",
              "       [ 0.24372803, -0.14749539,  0.02260449, -0.09001815,  0.07485964,\n",
              "         0.07919444,  0.04807313, -0.06129366]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "model = 'Helsinki-NLP/opus-mt-en-hi'\n",
        "tok = MarianTokenizer.from_pretrained(model)\n",
        "models = MarianMTModel.from_pretrained(model)"
      ],
      "metadata": {
        "id": "SQVpn718m1EI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = ['Hitanshi is mad']\n",
        "\n",
        "tok_input = tok(input_text,return_tensors='pt', padding = True, truncation = True)"
      ],
      "metadata": {
        "id": "Y1OABdrtsO0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate = models.generate(**tok_input)"
      ],
      "metadata": {
        "id": "m-3ITcaAoiHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = tok.batch_decode(translate, skip_special_tokens=True)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV9POthtrc98",
        "outputId": "bfe3595f-92e7-4136-8139-eaf34875f15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['हिटशी पागल है']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Topics -\n",
        "Read them thoroughly\n",
        "* NumPy\n",
        "* Pytorch\n",
        "* Keras\n",
        "* TensorFlow\n",
        "* SeaBorn\n",
        "* MatPlotLib\n",
        "* NLTK\n",
        "* Transformer (Hugging Face Library)\n",
        "* Gensim\n",
        "* Langdetect\n",
        "* OpenCV\n",
        "* PILLOW (pil)\n",
        "* TorchVision\n",
        "* FastAI"
      ],
      "metadata": {
        "id": "j-XRPytgrnxB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make CNN mask detection using CNN and Open CV"
      ],
      "metadata": {
        "id": "2IuYBzd-trE-"
      }
    }
  ]
}