{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgv6/n6Ww2kpNdgujoMwrd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thekhush11/GenAI-Colab-Projects/blob/main/Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25/07/2025"
      ],
      "metadata": {
        "id": "J9B_NaPtlz94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Topics -\n",
        "* Backpropogation and Optimization\n",
        "* Overfitting and Regularization\n",
        "* About the Pytorch"
      ],
      "metadata": {
        "id": "QenfCunCoaAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backpropogation -\n",
        "It is the learning algorithm that allow our neural network to learn by adjusting weights based on the error(loss)\n",
        "\n",
        "#Steps-\n",
        "1. Forward Pass - Input data is fed through the network layer by layer, with each neuron calculating a weighted sum of its inputs and applying an activation function. This process culminates in a predicted output from the output layer.\n"
      ],
      "metadata": {
        "id": "tkn7Z6xGnEy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "Qg-g1YtGmK1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Iris Data -\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer, StandardScaler"
      ],
      "metadata": {
        "id": "s86NpMCSpGg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "print(x, \"\\n\")\n",
        "\n",
        "print(y, \"\\n\")\n",
        "\n",
        "print(np.unique(x), \"\\n\")\n",
        "print(np.unique(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jsSGQ4c1qDpi",
        "outputId": "31900fa0-b59d-474f-b4c3-d0a540e8ab6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]] \n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2] \n",
            "\n",
            "[0.1 0.2 0.3 0.4 0.5 0.6 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.  2.1\n",
            " 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9\n",
            " 4.  4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5.  5.1 5.2 5.3 5.4 5.5 5.6 5.7\n",
            " 5.8 5.9 6.  6.1 6.2 6.3 6.4 6.5 6.6 6.7 6.8 6.9 7.  7.1 7.2 7.3 7.4 7.6\n",
            " 7.7 7.9] \n",
            "\n",
            "[0 1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use LabelBinarizer\n",
        "data = LabelBinarizer()\n",
        "data1 = data.fit_transform(y)\n",
        "\n",
        "#Normalizer Feature\n",
        "scaler = StandardScaler()\n",
        "Scaled = scaler.fit_transform(x)\n",
        "\n",
        "print(Scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o3Ob-tECqVQ4",
        "outputId": "a7ea447c-ecad-4155-b2e6-ba39d92856a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00 -1.31979479e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.38535265e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.50652052e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.24920112e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-5.37177559e-01  1.93979142e+00 -1.16971425e+00 -1.05217993e+00]\n",
            " [-1.50652052e+00  7.88807586e-01 -1.34022653e+00 -1.18381211e+00]\n",
            " [-1.02184904e+00  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.74885626e+00 -3.62176246e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.44707648e+00]\n",
            " [-5.37177559e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00  7.88807586e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.44707648e+00]\n",
            " [-1.87002413e+00 -1.31979479e-01 -1.51073881e+00 -1.44707648e+00]\n",
            " [-5.25060772e-02  2.16998818e+00 -1.45390138e+00 -1.31544430e+00]\n",
            " [-1.73673948e-01  3.09077525e+00 -1.28338910e+00 -1.05217993e+00]\n",
            " [-5.37177559e-01  1.93979142e+00 -1.39706395e+00 -1.05217993e+00]\n",
            " [-9.00681170e-01  1.01900435e+00 -1.34022653e+00 -1.18381211e+00]\n",
            " [-1.73673948e-01  1.70959465e+00 -1.16971425e+00 -1.18381211e+00]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.28338910e+00 -1.18381211e+00]\n",
            " [-5.37177559e-01  7.88807586e-01 -1.16971425e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  1.47939788e+00 -1.28338910e+00 -1.05217993e+00]\n",
            " [-1.50652052e+00  1.24920112e+00 -1.56757623e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  5.58610819e-01 -1.16971425e+00 -9.20547742e-01]\n",
            " [-1.26418478e+00  7.88807586e-01 -1.05603939e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00 -1.31979479e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  7.88807586e-01 -1.22655167e+00 -1.05217993e+00]\n",
            " [-7.79513300e-01  1.01900435e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-7.79513300e-01  7.88807586e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.38535265e+00  3.28414053e-01 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.26418478e+00  9.82172869e-02 -1.22655167e+00 -1.31544430e+00]\n",
            " [-5.37177559e-01  7.88807586e-01 -1.28338910e+00 -1.05217993e+00]\n",
            " [-7.79513300e-01  2.40018495e+00 -1.28338910e+00 -1.44707648e+00]\n",
            " [-4.16009689e-01  2.63038172e+00 -1.34022653e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  9.82172869e-02 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  3.28414053e-01 -1.45390138e+00 -1.31544430e+00]\n",
            " [-4.16009689e-01  1.01900435e+00 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.14301691e+00  1.24920112e+00 -1.34022653e+00 -1.44707648e+00]\n",
            " [-1.74885626e+00 -1.31979479e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-9.00681170e-01  7.88807586e-01 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.01900435e+00 -1.39706395e+00 -1.18381211e+00]\n",
            " [-1.62768839e+00 -1.74335684e+00 -1.39706395e+00 -1.18381211e+00]\n",
            " [-1.74885626e+00  3.28414053e-01 -1.39706395e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  1.01900435e+00 -1.22655167e+00 -7.88915558e-01]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.05603939e+00 -1.05217993e+00]\n",
            " [-1.26418478e+00 -1.31979479e-01 -1.34022653e+00 -1.18381211e+00]\n",
            " [-9.00681170e-01  1.70959465e+00 -1.22655167e+00 -1.31544430e+00]\n",
            " [-1.50652052e+00  3.28414053e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [-6.58345429e-01  1.47939788e+00 -1.28338910e+00 -1.31544430e+00]\n",
            " [-1.02184904e+00  5.58610819e-01 -1.34022653e+00 -1.31544430e+00]\n",
            " [ 1.40150837e+00  3.28414053e-01  5.35408562e-01  2.64141916e-01]\n",
            " [ 6.74501145e-01  3.28414053e-01  4.21733708e-01  3.95774101e-01]\n",
            " [ 1.28034050e+00  9.82172869e-02  6.49083415e-01  3.95774101e-01]\n",
            " [-4.16009689e-01 -1.74335684e+00  1.37546573e-01  1.32509732e-01]\n",
            " [ 7.95669016e-01 -5.92373012e-01  4.78571135e-01  3.95774101e-01]\n",
            " [-1.73673948e-01 -5.92373012e-01  4.21733708e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01  5.58610819e-01  5.35408562e-01  5.27406285e-01]\n",
            " [-1.14301691e+00 -1.51316008e+00 -2.60315415e-01 -2.62386821e-01]\n",
            " [ 9.16836886e-01 -3.62176246e-01  4.78571135e-01  1.32509732e-01]\n",
            " [-7.79513300e-01 -8.22569778e-01  8.07091462e-02  2.64141916e-01]\n",
            " [-1.02184904e+00 -2.43394714e+00 -1.46640561e-01 -2.62386821e-01]\n",
            " [ 6.86617933e-02 -1.31979479e-01  2.51221427e-01  3.95774101e-01]\n",
            " [ 1.89829664e-01 -1.97355361e+00  1.37546573e-01 -2.62386821e-01]\n",
            " [ 3.10997534e-01 -3.62176246e-01  5.35408562e-01  2.64141916e-01]\n",
            " [-2.94841818e-01 -3.62176246e-01 -8.98031345e-02  1.32509732e-01]\n",
            " [ 1.03800476e+00  9.82172869e-02  3.64896281e-01  2.64141916e-01]\n",
            " [-2.94841818e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
            " [-5.25060772e-02 -8.22569778e-01  1.94384000e-01 -2.62386821e-01]\n",
            " [ 4.32165405e-01 -1.97355361e+00  4.21733708e-01  3.95774101e-01]\n",
            " [-2.94841818e-01 -1.28296331e+00  8.07091462e-02 -1.30754636e-01]\n",
            " [ 6.86617933e-02  3.28414053e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 3.10997534e-01 -5.92373012e-01  1.37546573e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01 -1.28296331e+00  6.49083415e-01  3.95774101e-01]\n",
            " [ 3.10997534e-01 -5.92373012e-01  5.35408562e-01  8.77547895e-04]\n",
            " [ 6.74501145e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
            " [ 9.16836886e-01 -1.31979479e-01  3.64896281e-01  2.64141916e-01]\n",
            " [ 1.15917263e+00 -5.92373012e-01  5.92245988e-01  2.64141916e-01]\n",
            " [ 1.03800476e+00 -1.31979479e-01  7.05920842e-01  6.59038469e-01]\n",
            " [ 1.89829664e-01 -3.62176246e-01  4.21733708e-01  3.95774101e-01]\n",
            " [-1.73673948e-01 -1.05276654e+00 -1.46640561e-01 -2.62386821e-01]\n",
            " [-4.16009689e-01 -1.51316008e+00  2.38717193e-02 -1.30754636e-01]\n",
            " [-4.16009689e-01 -1.51316008e+00 -3.29657076e-02 -2.62386821e-01]\n",
            " [-5.25060772e-02 -8.22569778e-01  8.07091462e-02  8.77547895e-04]\n",
            " [ 1.89829664e-01 -8.22569778e-01  7.62758269e-01  5.27406285e-01]\n",
            " [-5.37177559e-01 -1.31979479e-01  4.21733708e-01  3.95774101e-01]\n",
            " [ 1.89829664e-01  7.88807586e-01  4.21733708e-01  5.27406285e-01]\n",
            " [ 1.03800476e+00  9.82172869e-02  5.35408562e-01  3.95774101e-01]\n",
            " [ 5.53333275e-01 -1.74335684e+00  3.64896281e-01  1.32509732e-01]\n",
            " [-2.94841818e-01 -1.31979479e-01  1.94384000e-01  1.32509732e-01]\n",
            " [-4.16009689e-01 -1.28296331e+00  1.37546573e-01  1.32509732e-01]\n",
            " [-4.16009689e-01 -1.05276654e+00  3.64896281e-01  8.77547895e-04]\n",
            " [ 3.10997534e-01 -1.31979479e-01  4.78571135e-01  2.64141916e-01]\n",
            " [-5.25060772e-02 -1.05276654e+00  1.37546573e-01  8.77547895e-04]\n",
            " [-1.02184904e+00 -1.74335684e+00 -2.60315415e-01 -2.62386821e-01]\n",
            " [-2.94841818e-01 -8.22569778e-01  2.51221427e-01  1.32509732e-01]\n",
            " [-1.73673948e-01 -1.31979479e-01  2.51221427e-01  8.77547895e-04]\n",
            " [-1.73673948e-01 -3.62176246e-01  2.51221427e-01  1.32509732e-01]\n",
            " [ 4.32165405e-01 -3.62176246e-01  3.08058854e-01  1.32509732e-01]\n",
            " [-9.00681170e-01 -1.28296331e+00 -4.30827696e-01 -1.30754636e-01]\n",
            " [-1.73673948e-01 -5.92373012e-01  1.94384000e-01  1.32509732e-01]\n",
            " [ 5.53333275e-01  5.58610819e-01  1.27429511e+00  1.71209594e+00]\n",
            " [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01]\n",
            " [ 1.52267624e+00 -1.31979479e-01  1.21745768e+00  1.18556721e+00]\n",
            " [ 5.53333275e-01 -3.62176246e-01  1.04694540e+00  7.90670654e-01]\n",
            " [ 7.95669016e-01 -1.31979479e-01  1.16062026e+00  1.31719939e+00]\n",
            " [ 2.12851559e+00 -1.31979479e-01  1.61531967e+00  1.18556721e+00]\n",
            " [-1.14301691e+00 -1.28296331e+00  4.21733708e-01  6.59038469e-01]\n",
            " [ 1.76501198e+00 -3.62176246e-01  1.44480739e+00  7.90670654e-01]\n",
            " [ 1.03800476e+00 -1.28296331e+00  1.16062026e+00  7.90670654e-01]\n",
            " [ 1.64384411e+00  1.24920112e+00  1.33113254e+00  1.71209594e+00]\n",
            " [ 7.95669016e-01  3.28414053e-01  7.62758269e-01  1.05393502e+00]\n",
            " [ 6.74501145e-01 -8.22569778e-01  8.76433123e-01  9.22302838e-01]\n",
            " [ 1.15917263e+00 -1.31979479e-01  9.90107977e-01  1.18556721e+00]\n",
            " [-1.73673948e-01 -1.28296331e+00  7.05920842e-01  1.05393502e+00]\n",
            " [-5.25060772e-02 -5.92373012e-01  7.62758269e-01  1.58046376e+00]\n",
            " [ 6.74501145e-01  3.28414053e-01  8.76433123e-01  1.44883158e+00]\n",
            " [ 7.95669016e-01 -1.31979479e-01  9.90107977e-01  7.90670654e-01]\n",
            " [ 2.24968346e+00  1.70959465e+00  1.67215710e+00  1.31719939e+00]\n",
            " [ 2.24968346e+00 -1.05276654e+00  1.78583195e+00  1.44883158e+00]\n",
            " [ 1.89829664e-01 -1.97355361e+00  7.05920842e-01  3.95774101e-01]\n",
            " [ 1.28034050e+00  3.28414053e-01  1.10378283e+00  1.44883158e+00]\n",
            " [-2.94841818e-01 -5.92373012e-01  6.49083415e-01  1.05393502e+00]\n",
            " [ 2.24968346e+00 -5.92373012e-01  1.67215710e+00  1.05393502e+00]\n",
            " [ 5.53333275e-01 -8.22569778e-01  6.49083415e-01  7.90670654e-01]\n",
            " [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.18556721e+00]\n",
            " [ 1.64384411e+00  3.28414053e-01  1.27429511e+00  7.90670654e-01]\n",
            " [ 4.32165405e-01 -5.92373012e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 3.10997534e-01 -1.31979479e-01  6.49083415e-01  7.90670654e-01]\n",
            " [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.18556721e+00]\n",
            " [ 1.64384411e+00 -1.31979479e-01  1.16062026e+00  5.27406285e-01]\n",
            " [ 1.88617985e+00 -5.92373012e-01  1.33113254e+00  9.22302838e-01]\n",
            " [ 2.49201920e+00  1.70959465e+00  1.50164482e+00  1.05393502e+00]\n",
            " [ 6.74501145e-01 -5.92373012e-01  1.04694540e+00  1.31719939e+00]\n",
            " [ 5.53333275e-01 -5.92373012e-01  7.62758269e-01  3.95774101e-01]\n",
            " [ 3.10997534e-01 -1.05276654e+00  1.04694540e+00  2.64141916e-01]\n",
            " [ 2.24968346e+00 -1.31979479e-01  1.33113254e+00  1.44883158e+00]\n",
            " [ 5.53333275e-01  7.88807586e-01  1.04694540e+00  1.58046376e+00]\n",
            " [ 6.74501145e-01  9.82172869e-02  9.90107977e-01  7.90670654e-01]\n",
            " [ 1.89829664e-01 -1.31979479e-01  5.92245988e-01  7.90670654e-01]\n",
            " [ 1.28034050e+00  9.82172869e-02  9.33270550e-01  1.18556721e+00]\n",
            " [ 1.03800476e+00  9.82172869e-02  1.04694540e+00  1.58046376e+00]\n",
            " [ 1.28034050e+00  9.82172869e-02  7.62758269e-01  1.44883158e+00]\n",
            " [-5.25060772e-02 -8.22569778e-01  7.62758269e-01  9.22302838e-01]\n",
            " [ 1.15917263e+00  3.28414053e-01  1.21745768e+00  1.44883158e+00]\n",
            " [ 1.03800476e+00  5.58610819e-01  1.10378283e+00  1.71209594e+00]\n",
            " [ 1.03800476e+00 -1.31979479e-01  8.19595696e-01  1.44883158e+00]\n",
            " [ 5.53333275e-01 -1.28296331e+00  7.05920842e-01  9.22302838e-01]\n",
            " [ 7.95669016e-01 -1.31979479e-01  8.19595696e-01  1.05393502e+00]\n",
            " [ 4.32165405e-01  7.88807586e-01  9.33270550e-01  1.44883158e+00]\n",
            " [ 6.86617933e-02 -1.31979479e-01  7.62758269e-01  7.90670654e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(Scaled, data1, test_size=0.2, random_state = 42)\n",
        "\n",
        "print(x_train.shape, \"\\n\")\n",
        "\n",
        "print(y_test.shape, \"\\n\")\n",
        "\n",
        "print(x_test.shape, \"\\n\")\n",
        "\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czCnYlmcrAkC",
        "outputId": "3678e65b-11cc-4b16-fe8f-8e127e5f4741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120, 4) \n",
            "\n",
            "(30, 3) \n",
            "\n",
            "(30, 4) \n",
            "\n",
            "(120, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Model -\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "eQRHOnqCr0ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_creation():\n",
        "    model = Sequential([\n",
        "        Dense(10, activation = 'relu', kernel_regularizer = regularizers.l1(0.01), input_shape = (4,)),\n",
        "        Dense(3, activation = 'softmax')\n",
        "        ])\n",
        "\n",
        "    model.compile(\n",
        "            optimizer = SGD(learning_rate = 0.1),\n",
        "            loss = CategoricalCrossentropy(),\n",
        "            metrics = ['accuracy']\n",
        "        )\n",
        "    return model"
      ],
      "metadata": {
        "id": "rvrx3knttYNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = model_creation()\n",
        "pred1 = model1.predict(x_test)\n",
        "print(pred1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a-WxrP-Buw4K",
        "outputId": "1e481ee5-85c8-4695-fd6a-7591cdc76bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "[[0.25510025 0.38034478 0.36455494]\n",
            " [0.17330354 0.4901253  0.3365712 ]\n",
            " [0.42276216 0.2913186  0.28591934]\n",
            " [0.26557148 0.36988214 0.36454654]\n",
            " [0.4325919  0.2807165  0.28669155]\n",
            " [0.2132721  0.42527443 0.36145335]\n",
            " [0.25130206 0.37345335 0.3752445 ]\n",
            " [0.39144152 0.29927102 0.3092874 ]\n",
            " [0.20583883 0.37355992 0.42060128]\n",
            " [0.24040003 0.37349424 0.38610578]\n",
            " [0.32072395 0.34917015 0.33010593]\n",
            " [0.18214723 0.46454486 0.35330787]\n",
            " [0.19924994 0.43481827 0.36593172]\n",
            " [0.18223602 0.4713164  0.34644762]\n",
            " [0.14384258 0.5734287  0.28272867]\n",
            " [0.31985876 0.35610202 0.32403925]\n",
            " [0.2371765  0.39530495 0.3675185 ]\n",
            " [0.16215293 0.41421437 0.42363265]\n",
            " [0.1817243  0.4188551  0.3994206 ]\n",
            " [0.22886702 0.38913888 0.38199416]\n",
            " [0.17069222 0.52064264 0.3086651 ]\n",
            " [0.24779618 0.3834673  0.36873654]\n",
            " [0.19453011 0.4906893  0.3147805 ]\n",
            " [0.23402219 0.3882511  0.37772664]\n",
            " [0.32275173 0.38476577 0.2924825 ]\n",
            " [0.32200152 0.33414337 0.3438551 ]\n",
            " [0.2431319  0.37838423 0.3784839 ]\n",
            " [0.30233285 0.36593765 0.3317296 ]\n",
            " [0.20119518 0.4470268  0.3517781 ]\n",
            " [0.18259983 0.48551556 0.33188456]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model with Backpropagation\n",
        "model2 = model_creation()\n",
        "model2.fit(x_train, y_train, epochs = 100)\n",
        "pred2 = model2.predict(x_test)\n",
        "print(pred2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PA7wlD07xIvu",
        "outputId": "3887f89e-d7fb-486a-b5c8-c77f3acf4835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3679 - loss: 1.2880  \n",
            "Epoch 2/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5648 - loss: 1.0916 \n",
            "Epoch 3/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8052 - loss: 0.9337\n",
            "Epoch 4/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8435 - loss: 0.8332\n",
            "Epoch 5/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8227 - loss: 0.7515\n",
            "Epoch 6/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8385 - loss: 0.6686\n",
            "Epoch 7/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8573 - loss: 0.6431 \n",
            "Epoch 8/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8271 - loss: 0.6412\n",
            "Epoch 9/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8358 - loss: 0.6136 \n",
            "Epoch 10/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8554 - loss: 0.5519\n",
            "Epoch 11/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8665 - loss: 0.5470\n",
            "Epoch 12/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8842 - loss: 0.5246\n",
            "Epoch 13/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8602 - loss: 0.5150 \n",
            "Epoch 14/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8656 - loss: 0.4953\n",
            "Epoch 15/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8971 - loss: 0.4741\n",
            "Epoch 16/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8888 - loss: 0.4672 \n",
            "Epoch 17/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8990 - loss: 0.4457\n",
            "Epoch 18/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9046 - loss: 0.4528 \n",
            "Epoch 19/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9035 - loss: 0.4371 \n",
            "Epoch 20/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8902 - loss: 0.4408\n",
            "Epoch 21/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9133 - loss: 0.4057 \n",
            "Epoch 22/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9185 - loss: 0.4073\n",
            "Epoch 23/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9258 - loss: 0.3860 \n",
            "Epoch 24/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8946 - loss: 0.4210 \n",
            "Epoch 25/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8917 - loss: 0.4093\n",
            "Epoch 26/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9146 - loss: 0.3979\n",
            "Epoch 27/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.3861\n",
            "Epoch 28/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9179 - loss: 0.3675 \n",
            "Epoch 29/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9369 - loss: 0.3710\n",
            "Epoch 30/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9390 - loss: 0.3562 \n",
            "Epoch 31/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9317 - loss: 0.3468\n",
            "Epoch 32/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9306 - loss: 0.3632 \n",
            "Epoch 33/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9473 - loss: 0.3443\n",
            "Epoch 34/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9413 - loss: 0.3473\n",
            "Epoch 35/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9558 - loss: 0.3187\n",
            "Epoch 36/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9392 - loss: 0.3353\n",
            "Epoch 37/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9329 - loss: 0.3343 \n",
            "Epoch 38/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9394 - loss: 0.3352\n",
            "Epoch 39/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9558 - loss: 0.3159\n",
            "Epoch 40/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9383 - loss: 0.3214\n",
            "Epoch 41/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.3088\n",
            "Epoch 42/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9465 - loss: 0.3041\n",
            "Epoch 43/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9650 - loss: 0.3056\n",
            "Epoch 44/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9413 - loss: 0.3054 \n",
            "Epoch 45/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9215 - loss: 0.3191\n",
            "Epoch 46/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9706 - loss: 0.2738\n",
            "Epoch 47/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 0.2929\n",
            "Epoch 48/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9604 - loss: 0.2834 \n",
            "Epoch 49/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9667 - loss: 0.2705\n",
            "Epoch 50/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9635 - loss: 0.2810 \n",
            "Epoch 51/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9627 - loss: 0.2711 \n",
            "Epoch 52/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9573 - loss: 0.2647\n",
            "Epoch 53/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.2585 \n",
            "Epoch 54/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9523 - loss: 0.2893 \n",
            "Epoch 55/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.2543\n",
            "Epoch 56/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.2678\n",
            "Epoch 57/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.2601\n",
            "Epoch 58/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9617 - loss: 0.2577\n",
            "Epoch 59/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9677 - loss: 0.2453\n",
            "Epoch 60/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9594 - loss: 0.2515\n",
            "Epoch 61/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9846 - loss: 0.2384 \n",
            "Epoch 62/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.2566 \n",
            "Epoch 63/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9585 - loss: 0.2528\n",
            "Epoch 64/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9479 - loss: 0.2569\n",
            "Epoch 65/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9565 - loss: 0.2493\n",
            "Epoch 66/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9752 - loss: 0.2309\n",
            "Epoch 67/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9752 - loss: 0.2288\n",
            "Epoch 68/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9408 - loss: 0.2596\n",
            "Epoch 69/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9773 - loss: 0.2148\n",
            "Epoch 70/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9596 - loss: 0.2349\n",
            "Epoch 71/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.2262 \n",
            "Epoch 72/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9596 - loss: 0.2304 \n",
            "Epoch 73/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9710 - loss: 0.2175\n",
            "Epoch 74/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9625 - loss: 0.2301 \n",
            "Epoch 75/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9700 - loss: 0.2212\n",
            "Epoch 76/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9740 - loss: 0.2101\n",
            "Epoch 77/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9731 - loss: 0.2067\n",
            "Epoch 78/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9700 - loss: 0.2145\n",
            "Epoch 79/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9625 - loss: 0.2135\n",
            "Epoch 80/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9679 - loss: 0.2076 \n",
            "Epoch 81/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.2243\n",
            "Epoch 82/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9646 - loss: 0.2005\n",
            "Epoch 83/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.2163 \n",
            "Epoch 84/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9710 - loss: 0.2068 \n",
            "Epoch 85/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9585 - loss: 0.2249\n",
            "Epoch 86/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9638 - loss: 0.2120 \n",
            "Epoch 87/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9771 - loss: 0.1944 \n",
            "Epoch 88/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9648 - loss: 0.2062 \n",
            "Epoch 89/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9542 - loss: 0.2154\n",
            "Epoch 90/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9583 - loss: 0.2069\n",
            "Epoch 91/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9583 - loss: 0.2140\n",
            "Epoch 92/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.1893\n",
            "Epoch 93/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9760 - loss: 0.1837\n",
            "Epoch 94/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9710 - loss: 0.1960\n",
            "Epoch 95/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9510 - loss: 0.2059\n",
            "Epoch 96/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9502 - loss: 0.2128\n",
            "Epoch 97/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.1955\n",
            "Epoch 98/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9510 - loss: 0.2030\n",
            "Epoch 99/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9646 - loss: 0.2058\n",
            "Epoch 100/100\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.1939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7cf744e1d9e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
            "[[8.77917465e-03 9.44690883e-01 4.65299897e-02]\n",
            " [9.77531672e-01 1.99388098e-02 2.52946420e-03]\n",
            " [6.79174832e-07 2.10587343e-04 9.99788761e-01]\n",
            " [9.07443557e-03 8.17955017e-01 1.72970474e-01]\n",
            " [4.46570665e-03 8.44433844e-01 1.51100382e-01]\n",
            " [9.56460714e-01 4.05341387e-02 3.00510833e-03]\n",
            " [3.12238298e-02 9.49043274e-01 1.97328683e-02]\n",
            " [1.43019992e-04 1.30731482e-02 9.86783862e-01]\n",
            " [1.49812608e-03 4.62599277e-01 5.35902619e-01]\n",
            " [1.51433256e-02 9.67875481e-01 1.69811547e-02]\n",
            " [1.36778329e-03 1.02349937e-01 8.96282256e-01]\n",
            " [9.83317673e-01 1.55540789e-02 1.12820149e-03]\n",
            " [9.79389787e-01 1.89431477e-02 1.66697067e-03]\n",
            " [9.84441161e-01 1.43780932e-02 1.18082413e-03]\n",
            " [9.93729651e-01 5.27039543e-03 9.99920652e-04]\n",
            " [1.23463785e-02 8.08434188e-01 1.79219380e-01]\n",
            " [5.02825460e-05 4.84582782e-03 9.95103836e-01]\n",
            " [1.47391865e-02 9.71816480e-01 1.34443864e-02]\n",
            " [1.37971584e-02 9.28357124e-01 5.78456447e-02]\n",
            " [3.44252949e-05 4.11757268e-03 9.95847940e-01]\n",
            " [9.89152253e-01 9.78534389e-03 1.06228027e-03]\n",
            " [2.89183925e-03 2.53971696e-01 7.43136406e-01]\n",
            " [9.79763150e-01 1.83288585e-02 1.90803187e-03]\n",
            " [6.59489451e-05 8.22782796e-03 9.91706252e-01]\n",
            " [1.12422509e-03 7.79791474e-02 9.20896649e-01]\n",
            " [8.14876985e-05 7.86559749e-03 9.92052913e-01]\n",
            " [9.95077207e-05 2.50576418e-02 9.74842906e-01]\n",
            " [4.60702686e-05 3.73460772e-03 9.96219337e-01]\n",
            " [9.67438638e-01 3.06723136e-02 1.88910868e-03]\n",
            " [9.81264353e-01 1.72858238e-02 1.44982454e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the Model -\n",
        "loss, acc = model2.evaluate(x_test, y_test)\n",
        "print(\"Loss:\", loss, \"\\n\")\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vra6hQAVyA1C",
        "outputId": "33c62fd7-d7f9-4568-dd00-f1a457e1c1dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.9667 - loss: 0.1763\n",
            "Loss: 0.17632439732551575 \n",
            "\n",
            "Accuracy: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid overfitting we have three methods -\n",
        "1. Increase Dataset Size\n",
        "2. Normalization\n",
        "3. Dropouts"
      ],
      "metadata": {
        "id": "m46dsbAG1GKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questions -\n",
        "1. What is Deep Learning?\n",
        "2. Tell about Deep Learning (feed forward layer)?\n",
        "3. What is Neural Network?\n",
        "4. What is Neurons?\n",
        "5. What is Flatten layer, Dense layer?\n",
        "6. What is activation function what is relu, tanh, softmax, sigmoid?\n",
        "7. What is CNN. How we can import and use it?\n",
        "8. What is filter?\n",
        "9. What is RNN. How we can import and use it?\n",
        "10. What is SimpleRNN and LSTM\n",
        "11. What is Optimizer?\n",
        "12. What is Backpropagation?\n",
        "13. What is Regularization and it techniques (L1 & L2)?\n",
        "14. What is Overfitting and Underfitting and how to avoid them?\n",
        "15. what is Dropout (method of avoiding overfitting)?\n",
        "16. Why we need Backpropagation and Optimizer?\n",
        "17. What is Pixel(28/28, 1D, 784)?"
      ],
      "metadata": {
        "id": "FM78_Oly1rcX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1W-LU8jZyn1i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}